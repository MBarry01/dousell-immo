/**
 * üöÄ PATTERNS DE CACHE AVANC√âS - Dousell Immo
 *
 * Optimisations pour aller au-del√† du Cache-Aside basique :
 * 1. Stale-While-Revalidate (SWR) - R√©ponse instantan√©e 100%
 * 2. Compression automatique - √âconomie RAM
 * 3. M√©triques & Observabilit√© - Monitoring production
 *
 * @see REDIS_CACHE_STRATEGY.md
 */

import { redis } from './redis-client';
import { getOrSetCache, type CacheOptions } from './cache-aside';

// ============================================================================
// 1. STALE-WHILE-REVALIDATE (SWR) PATTERN
// ============================================================================

/**
 * Pattern SWR : Toujours servir instantan√©ment (m√™me si stale)
 *
 * Workflow :
 * 1. Lecture cache ‚Üí Si existe : return imm√©diatement
 * 2. En parall√®le : V√©rifier si stale (>TTL/2)
 * 3. Si stale : Rafra√Æchir en background (non-bloquant)
 *
 * Avantages :
 * - Latence TOUJOURS 5ms (jamais 300ms)
 * - UX parfaite (aucun d√©lai per√ßu)
 * - DB moins sollicit√©e (refresh async)
 *
 * Trade-off :
 * - Donn√©es peuvent avoir max TTL/2 de retard
 *
 * @example
 * // Au lieu de getOrSetCache classique
 * const data = await getOrSetCacheSWR(
 *   'homepage_data',
 *   fetchFromDB,
 *   { ttl: 600 } // Max 5 min de retard (600/2)
 * );
 */
export async function getOrSetCacheSWR<T>(
  key: string,
  fetcher: () => Promise<T>,
  options: CacheOptions = {}
): Promise<T> {
  const {
    ttl = 3600,
    namespace = 'dousell',
    debug = process.env.NODE_ENV === 'development',
  } = options;

  const fullKey = `${namespace}:${key}`;
  const metaKey = `${fullKey}:meta`; // Stocke timestamp

  try {
    // 1. Lire cache (rapide - non bloquant)
    const cachedData = await redis.get(fullKey);
    const cachedMeta = await redis.get(metaKey);

    if (cachedData) {
      const data = JSON.parse(cachedData);

      // 2. V√©rifier si stale (>50% du TTL √©coul√©)
      const cacheAge = cachedMeta ? Date.now() - parseInt(cachedMeta) : ttl * 1000;
      const isStale = cacheAge > (ttl * 1000) / 2;

      if (isStale) {
        if (debug) console.log(`‚ö†Ô∏è  STALE DATA: ${fullKey} (refreshing in background...)`);

        // 3. Rafra√Æchir en BACKGROUND (non-bloquant !)
        // Ne pas attendre le r√©sultat
        refreshInBackground(fullKey, metaKey, fetcher, ttl, debug).catch((err) => {
          console.error(`Background refresh failed for ${fullKey}:`, err);
        });
      } else if (debug) {
        console.log(`üöÄ SWR HIT (fresh): ${fullKey}`);
      }

      // 4. Retourner imm√©diatement les donn√©es (m√™me si stale)
      return data;
    }

    // 5. Cache MISS : Fetch bloquant (1√®re fois seulement)
    if (debug) console.log(`üêå SWR MISS: ${fullKey} (initial fetch...)`);

    const freshData = await fetcher();

    // 6. Stocker avec m√©tadata timestamp
    await Promise.all([
      redis.set(fullKey, JSON.stringify(freshData), ttl),
      redis.set(metaKey, Date.now().toString(), ttl),
    ]);

    return freshData;
  } catch (error) {
    console.error(`SWR error for ${fullKey}:`, error);

    // Fallback : Si cache fail, fetch direct
    return fetcher();
  }
}

/**
 * Rafra√Æchissement asynchrone en background
 * Ne bloque jamais la r√©ponse utilisateur
 */
async function refreshInBackground<T>(
  dataKey: string,
  metaKey: string,
  fetcher: () => Promise<T>,
  ttl: number,
  debug: boolean
): Promise<void> {
  try {
    const freshData = await fetcher();

    await Promise.all([
      redis.set(dataKey, JSON.stringify(freshData), ttl),
      redis.set(metaKey, Date.now().toString(), ttl),
    ]);

    if (debug) console.log(`‚úÖ Background refresh complete: ${dataKey}`);
  } catch (error) {
    console.error(`Background refresh failed for ${dataKey}:`, error);
  }
}

// ============================================================================
// 2. COMPRESSION AUTOMATIQUE
// ============================================================================

/**
 * Cache avec compression automatique (pour gros objets)
 *
 * Cas d'usage :
 * - Liste de 1000+ propri√©t√©s (JSON >100KB)
 * - Objets avec beaucoup de texte (descriptions, HTML)
 * - √âconomie RAM Redis : 70-90% selon les donn√©es
 *
 * Trade-off :
 * - CPU : +2ms pour compress/decompress
 * - RAM : -80% en moyenne
 *
 * @example
 * const data = await getOrSetCacheCompressed(
 *   'big_list',
 *   fetchBigData,
 *   { ttl: 600, compressionThreshold: 10000 } // Compresse si >10KB
 * );
 */
export async function getOrSetCacheCompressed<T>(
  key: string,
  fetcher: () => Promise<T>,
  options: CacheOptions & { compressionThreshold?: number } = {}
): Promise<T> {
  const {
    ttl = 3600,
    namespace = 'dousell',
    debug = process.env.NODE_ENV === 'development',
    compressionThreshold = 5000, // 5KB par d√©faut
  } = options;

  const fullKey = `${namespace}:${key}`;
  const isCompressedKey = `${fullKey}:compressed`;

  try {
    // 1. Lire cache
    const cachedData = await redis.get(fullKey);
    const isCompressed = (await redis.get(isCompressedKey)) === 'true';

    if (cachedData) {
      if (debug) console.log(`üöÄ CACHE HIT (compressed: ${isCompressed}): ${fullKey}`);

      // D√©compresser si n√©cessaire
      if (isCompressed) {
        const decompressed = await decompress(cachedData);
        return JSON.parse(decompressed);
      }

      return JSON.parse(cachedData);
    }

    // 2. Cache MISS
    if (debug) console.log(`üêå CACHE MISS: ${fullKey}`);

    const freshData = await fetcher();
    const jsonString = JSON.stringify(freshData);
    const shouldCompress = jsonString.length > compressionThreshold;

    // 3. Compresser si gros objet
    if (shouldCompress) {
      const compressed = await compress(jsonString);

      if (debug) {
        const ratio = ((1 - compressed.length / jsonString.length) * 100).toFixed(1);
        console.log(
          `üíæ CACHE SET (compressed): ${fullKey} (${jsonString.length} ‚Üí ${compressed.length} bytes, -${ratio}%)`
        );
      }

      await Promise.all([
        redis.set(fullKey, compressed, ttl),
        redis.set(isCompressedKey, 'true', ttl),
      ]);
    } else {
      if (debug) console.log(`üíæ CACHE SET (no compression): ${fullKey} (${jsonString.length} bytes)`);

      await redis.set(fullKey, jsonString, ttl);
    }

    return freshData;
  } catch (error) {
    console.error(`Compressed cache error for ${fullKey}:`, error);
    return fetcher();
  }
}

/**
 * Compression simple avec Buffer (natif Node.js)
 * Utilise gzip (bon ratio compression/vitesse)
 */
async function compress(data: string): Promise<string> {
  const { gzip } = await import('zlib');
  const { promisify } = await import('util');

  const gzipAsync = promisify(gzip);
  const compressed = await gzipAsync(Buffer.from(data, 'utf-8'));
  return compressed.toString('base64');
}

/**
 * D√©compression
 */
async function decompress(data: string): Promise<string> {
  const { gunzip } = await import('zlib');
  const { promisify } = await import('util');

  const gunzipAsync = promisify(gunzip);
  const decompressed = await gunzipAsync(Buffer.from(data, 'base64'));
  return decompressed.toString('utf-8');
}

// ============================================================================
// 3. M√âTRIQUES & OBSERVABILIT√â
// ============================================================================

/**
 * M√©triques de cache pour monitoring production
 */
export class CacheMetrics {
  private static hits = 0;
  private static misses = 0;
  private static errors = 0;
  private static totalLatency = 0;
  private static operationCount = 0;

  /**
   * Enregistrer un cache HIT
   */
  static recordHit(latency: number) {
    this.hits++;
    this.totalLatency += latency;
    this.operationCount++;
  }

  /**
   * Enregistrer un cache MISS
   */
  static recordMiss(latency: number) {
    this.misses++;
    this.totalLatency += latency;
    this.operationCount++;
  }

  /**
   * Enregistrer une erreur
   */
  static recordError() {
    this.errors++;
  }

  /**
   * Obtenir les statistiques actuelles
   */
  static getStats() {
    const total = this.hits + this.misses;
    const hitRate = total > 0 ? (this.hits / total) * 100 : 0;
    const avgLatency = this.operationCount > 0 ? this.totalLatency / this.operationCount : 0;

    return {
      hits: this.hits,
      misses: this.misses,
      errors: this.errors,
      hitRate: hitRate.toFixed(2) + '%',
      avgLatency: avgLatency.toFixed(2) + 'ms',
      total,
    };
  }

  /**
   * R√©initialiser les compteurs (pour tests)
   */
  static reset() {
    this.hits = 0;
    this.misses = 0;
    this.errors = 0;
    this.totalLatency = 0;
    this.operationCount = 0;
  }

  /**
   * Logger les stats (appel√© p√©riodiquement ou √† la demande)
   */
  static logStats() {
    const stats = this.getStats();
    console.log('\nüìä CACHE METRICS:');
    console.log(`   Hits: ${stats.hits}`);
    console.log(`   Misses: ${stats.misses}`);
    console.log(`   Errors: ${stats.errors}`);
    console.log(`   Hit Rate: ${stats.hitRate}`);
    console.log(`   Avg Latency: ${stats.avgLatency}`);
    console.log(`   Total Operations: ${stats.total}\n`);
  }
}

/**
 * Cache avec m√©triques automatiques
 *
 * Utilisation :
 * - Remplace getOrSetCache dans les endpoints critiques
 * - Logs automatiques des hit/miss
 * - Int√©gration Datadog/Sentry possible
 *
 * @example
 * const data = await getOrSetCacheWithMetrics(
 *   'homepage_data',
 *   fetchFromDB,
 *   { ttl: 300 }
 * );
 *
 * // Plus tard, consulter les stats
 * CacheMetrics.logStats();
 */
export async function getOrSetCacheWithMetrics<T>(
  key: string,
  fetcher: () => Promise<T>,
  options: CacheOptions = {}
): Promise<T> {
  const startTime = Date.now();

  try {
    const data = await getOrSetCache(key, fetcher, options);
    const latency = Date.now() - startTime;

    // D√©tecter si c'√©tait un HIT ou MISS par la latence
    // HIT = <50ms, MISS = >100ms
    if (latency < 50) {
      CacheMetrics.recordHit(latency);
    } else {
      CacheMetrics.recordMiss(latency);
    }

    return data;
  } catch (error) {
    CacheMetrics.recordError();
    throw error;
  }
}

/**
 * Endpoint API pour exposer les m√©triques
 * √Ä ajouter dans app/api/cache-metrics/route.ts
 */
export function GET() {
  const stats = CacheMetrics.getStats();

  return Response.json({
    success: true,
    metrics: stats,
    timestamp: new Date().toISOString(),
  });
}

// ============================================================================
// 4. USAGE RECOMMAND√â POUR DOUSELL
// ============================================================================

/**
 * EXEMPLE : Homepage avec SWR (toujours instantan√©)
 */
// ...
export async function getHomePageSectionsSWR() {
  return getOrSetCacheSWR(
    'homepage_sections',
    async () => {
      // PROMISE MOCK POUR L'EXEMPLE
      // Dans la r√©alit√© : Promise.all([getLocations(), getVentes(), ...])
      return {
        locations: [],
        ventes: [],
        terrains: []
      };
    },
    {
      ttl: 600, // 10 minutes (max 5 min de retard acceptable)
      namespace: 'homepage',
      debug: true,
    }
  );
}

/**
 * EXEMPLE : Grande liste avec compression
 */
export async function getAllPropertiesCompressed() {
  return getOrSetCacheCompressed(
    'all_properties_full',
    async () => {
      // Requ√™te qui retourne 1000+ propri√©t√©s
      const supabase = await import('@/utils/supabase/server').then((m) => m.createClient());
      const { data } = await (await supabase).from('properties').select('*');
      return data || [];
    },
    {
      ttl: 300,
      namespace: 'properties',
      compressionThreshold: 10000, // Compresse si >10KB
      debug: true,
    }
  );
}

/**
 * EXEMPLE : Endpoint critique avec m√©triques
 */
export async function getCriticalDataWithMetrics(id: string) {
  return getOrSetCacheWithMetrics(
    `critical_${id}`,
    async () => {
      // Votre fetcher
      return { data: 'important' };
    },
    { ttl: 300, namespace: 'critical' }
  );
}
